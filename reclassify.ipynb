{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Automatic Domain Adaptation of Sentiment Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation using scikit-learn "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finance research evaluates the “tone” of a text to predict financial outcomes. Sentiment dictionaries are widely used: Harvard Psychosociological Dictionary, Harvard- IV-4 TagNeg (H4N), Loughran and McDonald (L&M) dictionary\n",
    "- Download dictionaries from here: https://sraf.nd.edu/textual-analysis/resources/#Master%20Dictionary\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "H4N_PATH = '/mounts/work/sedinkina/LoughranMcdonald2011_Dictionary/lm_data/LoughranMcDonald_MasterDictionary_2016.csv' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Sequence Number</th>\n",
       "      <th>Word Count</th>\n",
       "      <th>Word Proportion</th>\n",
       "      <th>Average Proportion</th>\n",
       "      <th>Std Dev</th>\n",
       "      <th>Doc Count</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Uncertainty</th>\n",
       "      <th>Litigious</th>\n",
       "      <th>Constraining</th>\n",
       "      <th>Superfluous</th>\n",
       "      <th>Interesting</th>\n",
       "      <th>Modal</th>\n",
       "      <th>Irr_Verb</th>\n",
       "      <th>Harvard_IV</th>\n",
       "      <th>Syllables</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AARDVARK</td>\n",
       "      <td>1</td>\n",
       "      <td>275</td>\n",
       "      <td>1.603442e-08</td>\n",
       "      <td>1.306189e-08</td>\n",
       "      <td>3.665256e-06</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12of12inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AARDVARKS</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1.749209e-10</td>\n",
       "      <td>1.028197e-11</td>\n",
       "      <td>1.014208e-08</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12of12inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABACI</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>4.664558e-10</td>\n",
       "      <td>1.465871e-10</td>\n",
       "      <td>6.401309e-08</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>12of12inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABACK</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>3.498419e-10</td>\n",
       "      <td>1.758203e-10</td>\n",
       "      <td>7.213526e-08</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12of12inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABACUS</td>\n",
       "      <td>5</td>\n",
       "      <td>6729</td>\n",
       "      <td>3.923477e-07</td>\n",
       "      <td>3.752169e-07</td>\n",
       "      <td>3.452425e-05</td>\n",
       "      <td>845</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>12of12inf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Word  Sequence Number  Word Count  Word Proportion  \\\n",
       "0   AARDVARK                1         275     1.603442e-08   \n",
       "1  AARDVARKS                2           3     1.749209e-10   \n",
       "2      ABACI                3           8     4.664558e-10   \n",
       "3      ABACK                4           6     3.498419e-10   \n",
       "4     ABACUS                5        6729     3.923477e-07   \n",
       "\n",
       "   Average Proportion       Std Dev  Doc Count  Negative  Positive  \\\n",
       "0        1.306189e-08  3.665256e-06         82         0         0   \n",
       "1        1.028197e-11  1.014208e-08          1         0         0   \n",
       "2        1.465871e-10  6.401309e-08          7         0         0   \n",
       "3        1.758203e-10  7.213526e-08          6         0         0   \n",
       "4        3.752169e-07  3.452425e-05        845         0         0   \n",
       "\n",
       "   Uncertainty  Litigious  Constraining  Superfluous  Interesting  Modal  \\\n",
       "0            0          0             0            0            0      0   \n",
       "1            0          0             0            0            0      0   \n",
       "2            0          0             0            0            0      0   \n",
       "3            0          0             0            0            0      0   \n",
       "4            0          0             0            0            0      0   \n",
       "\n",
       "   Irr_Verb  Harvard_IV  Syllables     Source  \n",
       "0         0           0          2  12of12inf  \n",
       "1         0           0          2  12of12inf  \n",
       "2         0           0          3  12of12inf  \n",
       "3         0           0          2  12of12inf  \n",
       "4         0           0          3  12of12inf  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "LMcD = pd.read_csv(H4N_PATH)\n",
    "LMcD.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reclassify L&M negative category:\n",
    "- first, convert data into a dictionary of labels and its words -> {label1: [word1, word2, ...], ...}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get L&M dictionary \n",
    "LMcD[\"Word\"] = LMcD[\"Word\"].str.lower()\n",
    "unc = LMcD.loc[lambda x: x[\"Uncertainty\"] > 0, \"Word\"].tolist()\n",
    "lit = LMcD.loc[lambda x: x[\"Litigious\"] > 0, \"Word\"].tolist()\n",
    "pos = LMcD.loc[lambda x: x[\"Positive\"] > 0, \"Word\"].tolist()\n",
    "neg =  LMcD.loc[lambda x: x[\"Negative\"] > 0, \"Word\"].tolist()\n",
    "LM_dict = {'Uncertainty':unc, 'Litigious': lit, 'Positive':pos, 'Negative': neg}\n",
    "\n",
    "#In L&M, word can have be a part of several categories\n",
    "LM_word_cl = defaultdict(list)\n",
    "for cl,words in LM_dict.items():\n",
    "    for w in words:\n",
    "        LM_word_cl[w].append(cl)\n",
    "\n",
    "#convert into a dictionary with two labels \n",
    "LABEL1 = 'Negative'\n",
    "LABEL2 = 'Common'\n",
    "target_dic = defaultdict(set)\n",
    "target_dic[LABEL1] = set(neg) #neg category\n",
    "target_dic[LABEL2] = set(unc+lit+pos) #other words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instead, you can also reclassify Harvard (H4N) dictionary:\n",
    "#LMcD[\"Word\"] = LMcD[\"Word\"].str.lower()\n",
    "#target_dic = defaultdict(set)\n",
    "#target_dic[LABEL1] = set(LMcD.loc[lambda x: x[\"Harvard_IV\"] > 0, \"Word\"].tolist())\n",
    "#target_dic[LABEL2] =set(LMcD.loc[lambda x: x[\"Harvard_IV\"] == 0, \"Word\"].tolist()) #[\"Harvard_IV\"] == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of all words in dictionary is 85221\n",
      "Number of Negative words in dictionary is 2355\n",
      "Number of Common words in dictionary is 1554\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of all words in dictionary is {LMcD.shape[0]}')\n",
    "print(f'Number of {LABEL1} words in dictionary is {len(target_dic[LABEL1])}')\n",
    "print(f'Number of {LABEL2} words in dictionary is {len(target_dic[LABEL2])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Load **domain specific** word embeddings of interest, e.g. learned from financial 10-K corpus and inspect them a little bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mounts/Users/student/sedinkina/.conda/envs/py36/lib/python3.6/site-packages/requests/__init__.py:80: RequestsDependencyWarning: urllib3 (1.24.3) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "EMB_PATH = '/mounts/work/sedinkina/models/preprocessed_doppelpunkt.vec'\n",
    "emb_model_fin = KeyedVectors.load_word2vec_format(EMB_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('rebounding', 0.5815426707267761),\n",
       " ('rebounded', 0.5602948665618896),\n",
       " ('soften', 0.5499194860458374),\n",
       " ('softening', 0.5360822677612305),\n",
       " ('slowdown', 0.533230185508728),\n",
       " ('sluggish', 0.5260505080223083),\n",
       " ('weak', 0.5184440612792969),\n",
       " ('slump', 0.5068018436431885),\n",
       " ('downturn', 0.5012232065200806)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_model_fin.most_similar('rebound', topn=9)#rebound is positive word in L&M dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train SVM classifier in a 5-fold cross validation setup:\n",
    "- using each trained classifier on the 5th fold to predict 20% of the dictionary\n",
    "- binary classification: using dictionary labels: LABEL1 and LABEL2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "    \n",
    "class SentimentAnalyser:\n",
    "\n",
    "    def __init__(self, dict_in: Dict[str, List[str]], emb_model: KeyedVectors): \n",
    "        \n",
    "        self.NUM_FOLDS = 5\n",
    "        self.dict_in = dict_in\n",
    "        self.emb_model = emb_model\n",
    "        self.word_to_cl = {w:cl for cl,words in dict_in.items() for w in words}\n",
    "        self.label1, self.label2 = dict_in.keys() \n",
    "        self.cl_to_int = {self.label1: 0, self.label2: 1}\n",
    "        self.reclassified = []\n",
    "    \n",
    "    def _split_data(self,data: List[str],i: int) -> List[List[str]] :\n",
    "        #train_data_pos = w[:int((len(data)+1)*.80)] #Remaining 80% to training set\n",
    "        #test_data_pos = w[int(len(data)*.80+1):] #Splits 20% data to test set\n",
    "\n",
    "        subset_size = round(len(data)/self.NUM_FOLDS)    \n",
    "        if i != self.NUM_FOLDS-1:\n",
    "            test_data_pos = data[i*subset_size:][:subset_size] \n",
    "            train_data_pos = data[:i*subset_size] + data[(i+1)*subset_size:]\n",
    "        else:\n",
    "            test_data_pos = data[i*subset_size:]\n",
    "            train_data_pos = data[:i*subset_size]\n",
    "        return train_data_pos, test_data_pos\n",
    "    \n",
    "    def _getProbs(self,predicted: np.ndarray, clf: SVC, test_data: List[str]) -> Dict[str, List[Tuple[str, float]]]:\n",
    "        \n",
    "        int_to_cl = {num:cl for cl, num in self.cl_to_int.items()}\n",
    "        probs = {}\n",
    "        classes = [self.word_to_cl[word] for word in test_data]\n",
    "        for i, el in enumerate(predicted):\n",
    "            word = test_data[i]\n",
    "            gold_class = classes[i]\n",
    "            probs[word] = [(int_to_cl[list(clf.classes_)[i]],x) for i,x in enumerate(el)]\n",
    "        return probs\n",
    "    \n",
    "    def _train(self,train_data: List[str], test_data: List[str], i:int) -> Dict[str, List[Tuple[str, float]]]:\n",
    "        \n",
    "        vectors = np.array([self.emb_model[word] for word in train_data])\n",
    "        classes = np.array([self.cl_to_int[self.word_to_cl[word]] for word in train_data])\n",
    "        clf = SVC(probability=True)\n",
    "        clf.fit(vectors, classes)  \n",
    "        vectors_test = np.array([self.emb_model[word] for word in test_data])\n",
    "        predicted = clf.predict_proba(vectors_test)\n",
    "        probs = self._getProbs(predicted,clf,test_data)\n",
    "        return probs    \n",
    "            \n",
    "    def get_data(self, thresh: int = 0.5) -> Dict[str, str]:\n",
    "        return {word:pred for prob, pred, word in self.reclassified if prob >=thresh}\n",
    "    \n",
    "    def get_df_data(self, thres: int = 0.5):\n",
    "        word_to_cl = self.get_data(thres)\n",
    "        words_old = sorted([w for cat, word_list in self.dict_in.items() for w in word_list])\n",
    "        cat = self.label1\n",
    "        csv_dict = defaultdict(list)\n",
    "        csv_dict['Word'] =  words_old\n",
    "        for w in words_old:\n",
    "            csv_dict[cat].append(int(word_to_cl.get(w, 0) == cat))\n",
    "        return pd.DataFrame(data=csv_dict)\n",
    "                \n",
    "    def reclassify(self):\n",
    "        \n",
    "        #words from dictionary for which we have embeddings\n",
    "        wordsInModel = list(filter(lambda x: x in self.emb_model, list(self.word_to_cl)))\n",
    "        print(f\"{len(wordsInModel)} of dictionary words are in embedding model (out of {len(self.word_to_cl)})\")\n",
    "        \n",
    "        wordsOfLabel1 = list(filter(lambda x: x in self.emb_model, self.dict_in[self.label1]))\n",
    "        print(f\"Number of {self.label1} words that are in embedding model is {len(wordsOfLabel1)}\")\n",
    "        \n",
    "        wordsOfLabel2 = list(filter(lambda x: x in self.emb_model, self.dict_in[self.label2]))\n",
    "        print(f\"Number of {self.label2} words that are in embedding model is {len(wordsOfLabel2)}\")\n",
    "        \n",
    "        for i in range(self.NUM_FOLDS):\n",
    "            print(f\"iteration {i+1}\")\n",
    "            \n",
    "            train_data_label1,test_data_label1 = self._split_data(wordsOfLabel1,i) #predict 20% of the dictionary\n",
    "            train_data_label2,test_data_label2 = self._split_data(wordsOfLabel2,i)\n",
    "\n",
    "            train_data_re = train_data_label1+train_data_label2\n",
    "            test_data_re = test_data_label1+test_data_label2\n",
    "            random.shuffle(train_data_re)\n",
    "            random.shuffle(test_data_re)    \n",
    "            \n",
    "            #print(f\"len of training data is {len(train_data_re)}\")\n",
    "            #print(f\"len of test is {len(test_data_re)}\")\n",
    "            probs = self._train(train_data_re,test_data_re,i)\n",
    "            for word,y in probs.items():     \n",
    "                pred,prob = sorted(y,key= lambda x:x[1],reverse=True)[0]\n",
    "                data = [prob,pred,word]\n",
    "                self.reclassified.append(data)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SentimentAnalyser recieves as an input old sentiment dictionary and domain specific embedding model\n",
    "reclassifier = SentimentAnalyser(dict_in = target_dic,\n",
    "                                 emb_model = emb_model_fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2965 of dictionary words are in embedding model (out of 3715)\n",
      "Number of Negative words that are in embedding model is 1893\n",
      "Number of Common words that are in embedding model is 1223\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n"
     ]
    }
   ],
   "source": [
    "#reclassify initial data\n",
    "reclassifier.reclassify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get reclassified words with probability >= 0.8 (turned to be the best for the prediction of finanical outcomes)\n",
    "dictionary_re = reclassifier.get_data(0.8) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reclassified Word   | New Class       Initial L&M Class\n",
      "\n",
      "uncontracted        | Negative        Litigious      \n",
      "uncertainly         | Negative        Uncertainty    \n",
      "possibly            | Negative        Uncertainty    \n",
      "probation           | Negative        Litigious      \n",
      "undetectable        | Negative        Uncertainty    \n",
      "warrantor           | Negative        Litigious      \n",
      "conceivably         | Negative        Uncertainty    \n",
      "rescissions         | Negative        Litigious      \n",
      "resolve             | Negative        Positive       \n",
      "speculation         | Negative        Uncertainty    \n",
      "rescinded           | Negative        Litigious      \n",
      "risking             | Negative        Uncertainty    \n",
      "recoupments         | Negative        Litigious      \n",
      "unconstitutional    | Negative        Litigious      \n",
      "regaining           | Negative        Positive       \n",
      "unusually           | Negative        Uncertainty    \n",
      "rebutting           | Negative        Litigious      \n",
      "contractile         | Negative        Litigious      \n",
      "unseasonable        | Negative        Uncertainty    \n",
      "suddenly            | Negative        Uncertainty    \n",
      "cautiousness        | Negative        Uncertainty    \n",
      "mediators           | Negative        Litigious      \n",
      "unusual             | Negative        Uncertainty    \n",
      "precautionary       | Negative        Uncertainty    \n",
      "unproved            | Negative        Uncertainty    \n",
      "sporadically        | Negative        Uncertainty    \n",
      "suggesting          | Negative        Uncertainty    \n",
      "excised             | Negative        Litigious      \n",
      "rectification       | Negative        Litigious      \n",
      "unenforceability    | Negative        Litigious      \n",
      "upturns             | Negative        Positive       \n",
      "permittee           | Negative        Litigious      \n",
      "constructively      | Negative        Positive       \n",
      "sudden              | Negative        Uncertainty    \n",
      "apparently          | Negative        Uncertainty    \n",
      "recalculations      | Negative        Uncertainty    \n",
      "defalcations        | Negative        Litigious      \n",
      "riskiness           | Negative        Uncertainty    \n",
      "mediated            | Negative        Litigious      \n",
      "remedied            | Negative        Litigious      \n",
      "instabilities       | Negative        Uncertainty    \n",
      "hidden              | Negative        Uncertainty    \n",
      "solves              | Negative        Positive       \n",
      "gain                | Negative        Positive       \n",
      "defalcation         | Negative        Litigious      \n",
      "rumors              | Negative        Uncertainty    \n"
     ]
    }
   ],
   "source": [
    "#get reclassified words\n",
    "print(\"\\n{:20}| {:15} {:15}\".format(\"Reclassified Word\", 'New Class', 'Initial L&M Class\\n'))\n",
    "\n",
    "for w, cl in dictionary_re.items():\n",
    "    if cl == LABEL1 and w not in target_dic[LABEL1]:\n",
    "        print(\"{:20}| {:15} {:15}\".format(w, cl, \" \".join(LM_word_cl[w])) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abandon</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abandoned</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abandoning</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abandonment</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abandonments</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>abandons</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>abdicated</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>abdicates</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>abdicating</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>abdication</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Word  Negative\n",
       "0       abandon         1\n",
       "1     abandoned         1\n",
       "2    abandoning         1\n",
       "3   abandonment         1\n",
       "4  abandonments         1\n",
       "5      abandons         1\n",
       "6     abdicated         0\n",
       "7     abdicates         0\n",
       "8    abdicating         0\n",
       "9    abdication         0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary_re_df = reclassifier.get_df_data(0.8) \n",
    "dictionary_re_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_re_df.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reclassify all L&M words and save results in .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentAnalyserFactory:\n",
    "    def create_analyzer(self,dict_in: Dict[str, List[str]], emb_model: KeyedVectors) -> SentimentAnalyser:\n",
    "        analyzer = SentimentAnalyser(dict_in, emb_model)\n",
    "        return analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reclassifying Uncertainty label...\n",
      "2965 of dictionary words are in embedding model (out of 3715)\n",
      "Number of Uncertainty words that are in embedding model is 275\n",
      "Number of Common words that are in embedding model is 2727\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "Reclassifying Litigious label...\n",
      "2965 of dictionary words are in embedding model (out of 3715)\n",
      "Number of Litigious words that are in embedding model is 622\n",
      "Number of Common words that are in embedding model is 2457\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "Reclassifying Positive label...\n",
      "2965 of dictionary words are in embedding model (out of 3715)\n",
      "Number of Positive words that are in embedding model is 326\n",
      "Number of Common words that are in embedding model is 2639\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "Reclassifying Negative label...\n",
      "2965 of dictionary words are in embedding model (out of 3715)\n",
      "Number of Negative words that are in embedding model is 1893\n",
      "Number of Common words that are in embedding model is 1223\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n"
     ]
    }
   ],
   "source": [
    "factory = SentimentAnalyserFactory()\n",
    "new_dict = {}\n",
    "for current_label, words in LM_dict.items():\n",
    "    print(f'Reclassifying {current_label} label...')\n",
    "    target_d = defaultdict(set)\n",
    "    target_d[current_label] = set(words) \n",
    "    rest = [w for l, w_list in LM_dict.items() if l != current_label for w in w_list]\n",
    "    target_d[LABEL2] = set(rest) #other words\n",
    "    \n",
    "    reclassifier = factory.create_analyzer(target_d,emb_model_fin)\n",
    "    reclassifier.reclassify()\n",
    "    \n",
    "    new_word_cl = reclassifier.get_data(0.8)  \n",
    "    new_cl_word = defaultdict(set)\n",
    "    for new_w, new_cl in new_word_cl.items():\n",
    "        new_cl_word[new_cl].add(new_w)\n",
    "\n",
    "    new_dict[current_label] = new_cl_word[current_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_word_cl = {w:cat for cat, d_words in new_dict.items() for w in d_words}\n",
    "words_LM = sorted(LM_word_cl.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat1, cat2, cat3, cat4 = new_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_dict = defaultdict(list)\n",
    "csv_dict['Word'] =  words_LM\n",
    "for w in words_LM:\n",
    "    csv_dict[cat1].append(int(all_word_cl.get(w, 0) == cat1))\n",
    "    csv_dict[cat2].append(int(all_word_cl.get(w, 0) == cat2))\n",
    "    csv_dict[cat3].append(int(all_word_cl.get(w, 0) == cat3))\n",
    "    csv_dict[cat4].append(int(all_word_cl.get(w, 0) == cat4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "reclassified_LM = pd.DataFrame(data=csv_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Uncertainty</th>\n",
       "      <th>Litigious</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3695</th>\n",
       "      <td>worse</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3696</th>\n",
       "      <td>worsen</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3697</th>\n",
       "      <td>worsened</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3698</th>\n",
       "      <td>worsening</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3699</th>\n",
       "      <td>worsens</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3700</th>\n",
       "      <td>worst</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3701</th>\n",
       "      <td>worthless</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3702</th>\n",
       "      <td>worthy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3703</th>\n",
       "      <td>writ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3704</th>\n",
       "      <td>writedown</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3705</th>\n",
       "      <td>writedowns</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3706</th>\n",
       "      <td>writeoff</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3707</th>\n",
       "      <td>writeoffs</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3708</th>\n",
       "      <td>writs</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3709</th>\n",
       "      <td>wrong</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3710</th>\n",
       "      <td>wrongdoing</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3711</th>\n",
       "      <td>wrongdoings</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3712</th>\n",
       "      <td>wrongful</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3713</th>\n",
       "      <td>wrongfully</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3714</th>\n",
       "      <td>wrongly</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Word  Uncertainty  Litigious  Positive  Negative\n",
       "3695        worse            0          0         0         1\n",
       "3696       worsen            0          0         0         1\n",
       "3697     worsened            0          0         0         1\n",
       "3698    worsening            0          0         0         1\n",
       "3699      worsens            0          0         0         1\n",
       "3700        worst            0          0         0         0\n",
       "3701    worthless            0          0         0         1\n",
       "3702       worthy            0          0         1         0\n",
       "3703         writ            0          0         0         0\n",
       "3704    writedown            0          0         0         1\n",
       "3705   writedowns            0          0         0         1\n",
       "3706     writeoff            0          0         0         0\n",
       "3707    writeoffs            0          0         0         1\n",
       "3708        writs            0          1         0         0\n",
       "3709        wrong            0          0         0         1\n",
       "3710   wrongdoing            0          0         0         0\n",
       "3711  wrongdoings            0          0         0         0\n",
       "3712     wrongful            0          0         0         1\n",
       "3713   wrongfully            0          0         0         0\n",
       "3714      wrongly            0          0         0         1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reclassified_LM.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "reclassified_LM.to_csv('reclassified_LM.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
